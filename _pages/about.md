---
permalink: /
title: "Welcome!"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi there! I am Ji-Ung, a PhD student at the UKP Lab at the Technical University of Darmstadt (Germany). My research revolves around efficient model training in natural language processing (NLP). This usually involves methods such as active learning that can handle low-resource scenarios with users who can provide the labels for queried instances. As I am also interested in (human) language learning, the evaluation of my methods often happen within the context of automated exercise generation and assessment. Finally, I am a big fan of user studies, having devised and conducted various evaluation studies involving citizen scientists. If you are interested in these research topics feel free to drop me a message! 

Activities
======

Workshop Organization
------
Since 2021, I am a part of the organizing team of the workshop on interactive learning for natural language processing (InterNLP). After a break in 2023, we are currently working on a new issue for 2024/25. If you are interested in joining the programme committee, please feel free to reach out! You can find all papers and talks of the past workshops below: 

* [InterNLP 2022](https://internlp.github.io/2022/index.html) (co-located with NeurIPS 2022)
* [InterNLP 2021](https://sites.google.com/view/internlp2021/home) (co-located with ACL 2021)

Community Engagement
------
Since 2019, I am a regular reviewer at major NLP and machine learning conferences (please check my [cv](https://ji-ung-lee.github.io/files/github-cv.pdf) for details). I have received outstanding reviewer awards, most notably at ACL 2020, EACL 2021, and ARR. I also review at various workshops such as [BEA](https://sig-edu.org/bea/).

Talks
------
* Invited talk: Facets of efficiency in NLP ([youtube](https://www.youtube.com/watch?v=Q6vs2nc2-HA)). KUIS AI, KoÂ¸c University. September, 2022.
* Spotlight talk: Investigating rational activation functions to train Transformer models. Dagstuhl Seminar on Efficient and Equitable Natural Language Processing in the Age of Deep Learning ([webpage](https://www.dagstuhl.de/en/seminars/seminar-calendar/seminar-details/22232)). June, 2022.

Teaching
------
* Winter 2019/20 and Winter 2020/21: Project coordinator of 50+ student software projects ([Bachelorpraktikum](https://www.informatik.tu-darmstadt.de/studium_fb20/im_studium/studiengaenge_liste/bachelor_praktikum.de.jsp))
* Summer 2018: Text analytics [course](https://www.tucan.tu-darmstadt.de/scripts/mgrqispi.dll?APPNAME=CampusNet&PRGNAME=COURSEDETAILS&ARGUMENTS=-N000000000000002,-N000608,-N0,-N365583171866414,-N365583171891415,-N0,-N0,-N0) on active learning for undergraduate and graduate students
* Student thesis supervision: During my PhD time, I had the pleasure to supervise 9 motivated students on their B.Sc. and M.Sc. thesis. 